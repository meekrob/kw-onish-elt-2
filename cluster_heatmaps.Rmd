---
title: "Clustering of modENCODE/Reinke ChIP-seq peaks"
author: "DC King - Onish lab"
date: "Spring 2019"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
options(repos = c(CRAN = "http://cran.rstudio.com"))
R.version
RStudio.Version()
library(pheatmap)
library(stringr)
library(reshape2)
library(ggplot2)
library(ggExtra)
library(RColorBrewer) # for pheatmap
library(GenomicRanges)
library(biomaRt)
library(ChIPpeakAnno)
library(topGO)
```

## Script version
```{bash repo version, echo=FALSE}

git remote -v
git log -n 1
git status -s | grep -v '^?'
git diff cluster_heatmaps.Rmd
```

## Process data
```{r get-data}
getwd()
# clear out environment
rm(list=ls())

# IDR peaks

# narrowPeak is bedlike. Each line contains - 
# The comprehensive range of two overlapping peaks.
# The comprehensive peak summit.
# The summit and ranges of the individual peaks.
# Score information.
source('scripts/makeGRangesFromNarrowPeak.R') # this script retains the extra columns and drops unused ones
L1_IDR = makeGRangesFromNarrowPeak('L1_1_L1_2.IDR_0.05.narrowPeak')
LE_IDR = makeGRangesFromNarrowPeak('LE_1_LE_2.IDR_0.05.narrowPeak')
L3_IDR = makeGRangesFromNarrowPeak('L3_1_L3_2.IDR_0.05.narrowPeak')
# Union of all IDR output, with peak maxes assigned via my modification of javaGenomicsToolkit https://github.com/meekrob/java-genomics-toolkit
df = read.table("allStagesUNION.IDR_0.05.sorted.bed_s.df", header=T, sep="\t")
dfG = makeGRangesFromDataFrame(df, 
                               keep.extra.columns = T, 
                               ignore.strand = T, 
                               starts.in.df.are.0based = T)

seqinfo(dfG) <- Seqinfo(c('chrI', 'chrII', 'chrIII', 'chrIV', 'chrV', 'chrX'), 
                    c(15072434, 15279421, 13783801, 17493829, 20924180, 17718942), 
                    c(FALSE, FALSE, FALSE, FALSE, FALSE, FALSE), 
                    c("ce11", "ce11", "ce11", "ce11", "ce11", "ce11"))
dfG$LE_IDR = FALSE
dfG$L1_IDR = FALSE
dfG$L3_IDR = FALSE

#### Mark which IDR peaks contributed to the union
LE_verify = GenomicRanges::findOverlaps(LE_IDR, dfG, type="any")
L1_verify = GenomicRanges::findOverlaps(L1_IDR, dfG, type="any")
L3_verify = GenomicRanges::findOverlaps(L3_IDR, dfG, type="any")
dfG$LE_IDR[ to(LE_verify) ] <- TRUE
dfG$L1_IDR[ to(L1_verify) ] <- TRUE
dfG$L3_IDR[ to(L3_verify) ] <- TRUE

source('scripts/r_isect_union.R')
dfG$summit_agreement = score_peak_summit_agreement(dfG, LE_IDR, L1_IDR, L3_IDR)$summit_agreement

# collect some variables 
IDR_sets = list(LE_IDR=LE_IDR,L1_IDR=L1_IDR,L3_IDR=L3_IDR,LE_verify=LE_verify,L1_verify=L1_verify,L3_verify=L3_verify)
rm(LE_IDR,L1_IDR,L3_IDR,LE_verify,L1_verify,L3_verify)


# Remove the unused javaGenomicsToolkit columns (min,mean,etc.)

all_max_col_ix = which(! is.na(str_match(colnames(df),"max")))
df_max = df[,all_max_col_ix]
dfG_metacolnames = colnames(mcols(dfG))
dfG_max_ix = which(! is.na(str_match(dfG_metacolnames,"max")))
max_colnames = dfG_metacolnames[ dfG_max_ix ]
dfG_max = dfG[,c(max_colnames, 'LE_IDR','L1_IDR','L3_IDR','summit_agreement')]
# index vars not used further
rm(all_max_col_ix, dfG_max_ix)

# remove the verbose parts of the filenames from the column labels
dfG_metacolnames = colnames(mcols(dfG_max))
columns_to_sanitize = which(! is.na(str_match(dfG_metacolnames,'input_z.bw')))
repnames=str_extract(dfG_metacolnames[columns_to_sanitize], "L[E,1,3]{1}_[1,2]{1}")
newcolnames = dfG_metacolnames
newcolnames[columns_to_sanitize] <- repnames
colnames(mcols(dfG_max)) <- newcolnames

colnames(df_max)<-c("max_log_L1_1_minus_log_L1_input", 
                    "max_log_L1_2_minus_log_L1_input", 
                    "max_log_L3_1_minus_log_L3_input", 
                    "max_log_L3_2_minus_log_L3_input", 
                    "max_log_LE_1_minus_log_LE_input",  
                    "max_log_LE_2_minus_log_LE_input")

colnames_in_stage_order = colnames(df_max)[c(5,6,1:4)]
position_columns = c("chrom","chromStart","chromEnd","ID")
# make numeric, with 
data6d = as.matrix(df_max[,colnames_in_stage_order])
data3d = data.frame( LE=rowMeans(data6d[,c(1,2)]),
                     L1=rowMeans(data6d[,c(3,4)]),
                     L3=rowMeans(data6d[,c(5,6)]))

# perform normalization on 3d
peaks3d_sd = apply(data3d, 1, sd)
peaks3d_mu = apply(data3d, 1, mean)
peaks3d_std = (data3d - peaks3d_mu) /  peaks3d_sd

# perform normalization on 6d (data)
peaks6d_sd = apply(data6d, 1, sd)
peaks6d_mu = apply(data6d, 1, mean)
# normalize by row
peaks6d_std = (data6d- peaks6d_mu) /  peaks6d_sd

# change filenames to shorter labels
colnames(peaks6d_std) <- c("LE_1", "LE_2", "L1_1", "L1_2", "L3_1","L3_2")

# changing versus not-changing
q.peaks6d_zeroed_nans_sd = function(q) { quantile(peaks6d_sd, q)}
q.peaks3d_zeroed_nans_sd = function(q) { quantile(peaks3d_sd, q)}

THRESHOLD = .05

# make the text conversions consistent
TXT_THRESHOLD = sprintf("%.3f", THRESHOLD)

# Enforce stdev-passing peaks and "all IDR" as part of the threshold
# w/reps
threshold6d_q = q.peaks6d_zeroed_nans_sd(THRESHOLD)
threshold6d_ix = peaks6d_sd > threshold6d_q
# to restrict to all IDR only
#threshold6d_ix = dfG$LE_IDR & dfG$L1_IDR & dfG$L3_IDR & threshold6d_ix
threshold6d_x = peaks6d_std[threshold6d_ix,]
# w/reps avg'd
threshold3d_q = q.peaks3d_zeroed_nans_sd(THRESHOLD)
threshold3d_ix = peaks3d_sd > threshold3d_q
# to restrict to all IDR only
#threshold3d_ix = dfG$LE_IDR & dfG$L1_IDR & dfG$L3_IDR & threshold3d_ix
threshold3d_x = peaks3d_std[threshold3d_ix,]

include6d_x = threshold6d_x
include3d_x = threshold3d_x

# clean up the environment some more
thresholded_data = list( w_reps = list(threshold6d_q=threshold6d_q,
                                       threshold6d_ix=threshold6d_ix,
                                       threshold6d_x=threshold6d_x,
                                       include6d_x=include6d_x),
                         reps_avd = list(threshold3d_q=threshold3d_q,
                                         threshold3d_ix=threshold3d_ix,
                                         threshold3d_x=threshold3d_x,
                                         include3d_x=include3d_x),
                         THRESHOLD=THRESHOLD,
                         TXT_THRESHOLD = sprintf("%.3f", THRESHOLD))

rm(threshold6d_q,threshold6d_ix,threshold6d_x,include6d_x,
   threshold3d_q,threshold3d_ix,threshold3d_x,include3d_x,
   THRESHOLD,TXT_THRESHOLD)

cat("Datasets: threshold at:", thresholded_data$TXT_THRESHOLD,"\n")
cat("include_x: reps not merged:", dim(thresholded_data$w_reps$include6d_x),"\n")
cat("include3d_x: reps merged:", dim(thresholded_data$reps_avd$include3d_x),"\n")
```

```{r cluster}
attach(thresholded_data)
source('scripts/reorder_kmeans.R')
nclust=4


label=paste(
  sprintf("kmeans clusters at std. dev. > %.3f,", 
          reps_avd$threshold3d_q), 
          "(excludes lower ", sprintf("%.1f%%)", 
          THRESHOLD*100))
clusters = list()

set.seed(31415)
pobj = pheatmap(reps_avd$include3d_x, kmeans=nclust, cluster_rows=F, cluster_cols = F, main=label)
clusters$kmeans_on3d_k4 = reorder_kmeans(pobj$kmeans)

heatmap_color = colorRampPalette(rev(brewer.pal(n = 7, name ="RdYlBu")))(100)
pheatmap(reps_avd$include3d_x[order(clusters$kmeans_on3d_k4$cluster),], cluster_rows=F, cluster_cols=F, color=heatmap_color, show_rownames=F)

set.seed(31415)
clusters$kmeans_on3d_k11 = reorder_kmeans(kmeans(reps_avd$include3d_x,11))

#### work with the 3d matrix as a circle in 2D
source('scripts/rotation_matrices.R')
circular_data3d = flatten_std( reps_avd$include3d_x ) # this seems not to be right, but since it's for vis. purposes, 
# xy coordinates range between -1,1, and polar coordinates all have radius=1, so I'm sticking with it for now.

# trend plot with 4 clusters
clusters$k4_trends = clusters$kmeans_on3d_k4$centers
rownames(clusters$k4_trends) <- c("LE-specific", "Post embryonic", "L3-high","Increasing")

clusters$k4_trends_long = melt(clusters$k4_trends)
colnames(clusters$k4_trends_long) <- c("description", "stage", "center")

label=paste(sprintf("%d cluster trends at std. dev. > %.3f,", nrow(clusters$k4_trends), reps_avd$threshold3d_q), "(excludes lower ", sprintf("%.1f%%)", THRESHOLD*100))
figure_colors = scale_colour_manual(values=c("#7570B3","#1B9E77","#D95F02","#E7298A"))
print(
  ggplot(clusters$k4_trends_long, 
         aes(x=stage,y=center, 
             group=description,
             colour=description)) + 
    geom_line(size = 2) + 
    labs(title="Kmeans cluster centers (k=4)", 
         y = "cluster center (Z)", 
         x = "developmental stage") + 
    figure_colors)

# for the figure, separate out the groups into a separate plot, lay them out vertically,
# and prevent the domain from expanding
print( # k4stacked.pdf, scrunch the "Plots" display in the right panel all the way down to real dimensions you expect in the 
       # Illustrator file.
    ggplot(clusters$k4_trends_long, 
           aes(x=stage,y=center, 
               group=description,
               colour=description)) + 
        geom_line(size = 2) + 
        labs(title="Kmeans cluster centers (k=4)", 
             y = "cluster center (Z)", 
             x = "developmental stage") + 
      figure_colors + facet_grid(description ~ .) +  
      theme(legend.position = "none",
            strip.text.y = element_blank(), # omit facet label
            aspect.ratio=1.4787/3,
            panel.spacing=unit(.7,"cm"),
            panel.background=element_rect(fill='white'),
            panel.grid.minor.y=element_line(colour='black',linetype = 'dashed',size=.5),
            panel.grid.major.y=element_line(colour='black',linetype = 'solid',size=.75), 
            panel.grid.major.x=element_line(colour='grey',linetype = 'solid',size=.5)) +
      scale_x_discrete(expand=rep(0,4)) + 
      scale_y_continuous(breaks = c(-1,0,1),
                         minor_breaks=c(-.5,.5)
                         )
)

rgb_colors = c("80,80,80",apply(t(col2rgb(c("#7570B3","#1B9E77","#D95F02","#E7298A"))),1, str_flatten, collapse = ',')) # includes grey for the 0 cluster

# trend plot with 11 clusters
clusters$k11_trends = as.data.frame(clusters$kmeans_on3d_k11$centers)
clusters$k11_trends$label <- sprintf("%d (%d)", 1:11, clusters$kmeans_on3d_k11$size)
clusters$k11_trends$lt700 = ifelse(clusters$kmeans_on3d_k11$size < 700, "cluster size < 700", "cluster size > 700")
k11_trends_long = melt(clusters$k11_trends)
k11_trends_long$label = factor(k11_trends_long$label, levels = clusters$k11_trends$label)
colnames(k11_trends_long) <- c("cluster","lt700","stage","center")
# the following list is a reorder of brewer.pal(11,"Paired")
almostHueSorted = c("#FFFF99","#FF7F00","#FB9A99","#E31A1C","#FDBF6F","#33A02C","#B2DF8A","#1F78B4","#A6CEE3", "#6A3D9A","#CAB2D6")
figure_colors = scale_colour_manual(name="cluster Id (size)", values=almostHueSorted)
print(
  ggplot(k11_trends_long, 
         aes(x=stage,y=center, 
             group=cluster,
             colour=cluster)) + 
    geom_line(size = 1.5) + 
    labs(title="Kmeans cluster centers (k=11)", 
         y = "cluster center (Z)", 
         x = "developmental stage") + 
    figure_colors + facet_grid(~ lt700) + 
    theme(panel.background=element_rect(fill='#E6E6E6'))
    
  )

source('scripts/kweights.R')
# The profiler points to rbind in the euclid/dist call as the main time sync.
# Maybe this can be avoided by pasting the cluster centers onto the data (a single call to rbind),
# then running dist() on the resulting table. The euclid function would then access the appropriate
# rows of the resultant output, called by weight_f(), which is applied over each center for each row
# of data, and summed inside row_func, which returns the reciprocal as the value of w[i][j].
clusters$k4weights = kweights(reps_avd$include3d_x, clusters$kmeans_on3d_k4$cluster, clusters$kmeans_on3d_k4$centers)
# laptop:
#    user  system elapsed 
#   17.295   0.227  18.562 
#clusters$k11weights = kweights(reps_avd$include3d_x, clusters$kmeans_on3d_k11$cluster, clusters$kmeans_on3d_k11$centers)
clusters$k11weights = rep(1,length(clusters$kmeans_on3d_k11$cluster)) # this takes too long, and we don't use it currently
# laptop:
#   user  system elapsed 
# 46.197   0.537  49.254

# The standard heatmaps. See https://stackoverflow.com/questions/36852101/r-legend-title-or-units-when-using-pheatmap for 
# getting the data out manually.
pheatmap(reps_avd$include3d_x[order(clusters$kmeans_on3d_k4$cluster,-clusters$k4weights),], cluster_rows=F, cluster_cols=F, color=heatmap_color, show_rownames=F)
pheatmap(reps_avd$include3d_x[order(clusters$kmeans_on3d_k11$cluster,-clusters$k11weights),], cluster_rows=F, cluster_cols=F, color=heatmap_color, show_rownames=F)


# add clusters and weights to GenomicRanges object
dfG_max$k4cluster = 0
dfG_max$k11cluster = 0
dfG_max$k4weights = 0
dfG_max$k11weights = 0
dfG_max$k4cluster[reps_avd$threshold3d_ix] <- clusters$kmeans_on3d_k4$cluster
dfG_max$k4weights[reps_avd$threshold3d_ix] = clusters$k4weights
dfG_max$k11cluster[reps_avd$threshold3d_ix] <- clusters$kmeans_on3d_k11$cluster
dfG_max$k11weights[reps_avd$threshold3d_ix] = clusters$k11weights

```

```{r format prepare BED+}
dfG_max$LE_nonNormed = (dfG_max$LE_1 + dfG_max$LE_2)/2
dfG_max$L1_nonNormed = (dfG_max$L1_1 + dfG_max$L1_2)/2
dfG_max$L3_nonNormed = (dfG_max$L3_1 + dfG_max$L3_2)/2
dfG_max$LE_std = peaks3d_std[,1]
dfG_max$L1_std = peaks3d_std[,2]
dfG_max$L3_std = peaks3d_std[,3]
# drop the individual rep columns
dfG_max$LE_1 = NULL
dfG_max$LE_2 = NULL
dfG_max$L1_1 = NULL
dfG_max$L1_2 = NULL
dfG_max$L3_1 = NULL
dfG_max$L3_2 = NULL

float_precision_string = "%.3f"
peaksForBigBed = dfG_max
peaksForBigBed$LE_IDR = as.integer(dfG_max$LE_IDR)
peaksForBigBed$L1_IDR = as.integer(dfG_max$L1_IDR)
peaksForBigBed$L3_IDR = as.integer(dfG_max$L3_IDR)
peaksForBigBed$name = sprintf("ELT2peak%05d", 1:length(peaksForBigBed))
peaksForBigBed$k4weights = sprintf(float_precision_string, peaksForBigBed$k4weights)
peaksForBigBed$k4labels = c(
  "Not-changing or not IDR-passing",
  "LE-specific",
  "Post-embryonic",
  "L3-high",
  "Increasing"
)[peaksForBigBed$k4cluster + 1]
peaksForBigBed$k11weights = sprintf(float_precision_string, peaksForBigBed$k11weights)
peaksForBigBed$variance = apply(mcols(peaksForBigBed)[,c('LE_nonNormed','L1_nonNormed','L3_nonNormed')], 1, var)
peaksForBigBed$LE_nonNormed = sprintf(float_precision_string, peaksForBigBed$LE_nonNormed)
peaksForBigBed$L1_nonNormed = sprintf(float_precision_string, peaksForBigBed$L1_nonNormed)
peaksForBigBed$L3_nonNormed = sprintf(float_precision_string, peaksForBigBed$L3_nonNormed)
peaksForBigBed$LE_std = sprintf(float_precision_string, peaksForBigBed$LE_std)
peaksForBigBed$L1_std = sprintf(float_precision_string, peaksForBigBed$L1_std)
peaksForBigBed$L3_std = sprintf(float_precision_string, peaksForBigBed$L3_std)



source('scripts/getCodingGenes.R',echo=F)
system.time({annotatedPeaks = getCodingGenes(peaksForBigBed)})
attach(annotatedPeaks)
kinases = read.table('kinases.bm',header=T,sep="\t")
mapping_breakdown = table(ap$insideFeature)
pie_labels = paste0(names(table(ap$insideFeature)), rep(" (",5), table(ap$insideFeature), rep(")",5))
pie(table(ap$insideFeature), labels=pie_labels, main="Peaks mapping nearest to a gene start or end", sub="paramart: wbps_gene_id, biotype= protein_coding")

peakSchema = "
table ELT2DynamicPeaks
\"ELT-2 Dynamic Peaks\"
(
string  chrom;		\"Reference sequence chromosome or scaffold\"
uint    chromStart;	\"Start position of feature on chromosome\"
uint    chromEnd;	\"End position of feature on chromosome\"
string  name;		\"Index of peak\"
string  WBID;   \"Wormbase ID\"
string mapping; \"How did it map to the gene?\"
uint  k4cluster;  \"Cluster assignment in kmeans = 4, 0 for not-changing\"
string  k4label; \"Description of the trend for cluster\"
string  k4weight;   \"Weight assigned to kmeans = 4 cluster assignment [0-1]\"
char[1] LE_IDR; \"0/1 IDR peak in Late embryo\"
char[1] L1_IDR; \"0/1 IDR peak in Stage 1 Larvae\"
char[1] L3_IDR; \"0/1 IDR peak in Stage 3 Larvae\"
string summit_agreement; \"Average bp difference in summit calls to mean\"
)"
write(peakSchema, "peaks.as")




# make a dataframe that is in the same order as above
write.table(data.frame(as.character(seqnames(annotatedPeaks$ap)),
                       start(annotatedPeaks$ap),
                       end(annotatedPeaks$ap),
                       annotatedPeaks$ap$name,
                       annotatedPeaks$ap$feature,
                       annotatedPeaks$ap$insideFeature,
                       annotatedPeaks$ap$k4cluster,
                       annotatedPeaks$ap$k4labels,
                       annotatedPeaks$ap$k4weights,
                       annotatedPeaks$ap$LE_IDR,
                       annotatedPeaks$ap$L1_IDR,
                       annotatedPeaks$ap$L3_IDR,
                       annotatedPeaks$ap$summit_agreement
                    
                       ), "peaksForBigBed.bed",quote=F,row.names=F,col.names=F,sep="\t")
chrom.sizes = "chrV	20924180
chrX	17718942
chrIV	17493829
chrII	15279421
chrI	15072434
chrIII	13783801
chrM	13794"
write(chrom.sizes,"chrom.sizes")
```

```{bash make bigBed}
# you must execute the above chunks first
# better figure out the PATH on your system
PATH=$PATH:/Users/david/bin/UCSC_userApps 
bedSort peaksForBigBed.bed peaksForBigBed.bed
bedToBigBed peaksForBigBed.bed chrom.sizes peaksForBigBed.bb -type=bed3+8 -tab -as=peaks.as
```

```{r Get Coding Genes}
# annotatedPeaks assigned in previous chunk
attach(annotatedPeaks)
 # a pie chart with the breakdown of how the annotation happened
mapping_breakdown = table(ap$insideFeature)
breakdown = list(`upstream` = mapping_breakdown['upstream'] +
                              mapping_breakdown['overlapStart'],
                 `inside` = mapping_breakdown['inside'] + 
                            mapping_breakdown['includeFeature'],
                 `downstream` = mapping_breakdown['downstream'] + 
                                mapping_breakdown['overlapEnd'],
                 `unmapped` = mapping_breakdown['unmapped ± 5Kb']
                 )

pie_labels = paste0(names(breakdown), rep(" (",4), unlist(breakdown), rep(")",4))
pie(unlist(breakdown), labels=pie_labels, main="Peaks mapping nearest to a gene", clockwise=T, init.angle=-90)

# upset plot: identify set overlap by assigned value of k
clustersPerGene = table(ap$feature, ap$k4cluster)
wbid_rownames = rownames(clustersPerGene)
# some bool vectors
wbid_names_k0_bool = clustersPerGene[,'0'] > 0
wbid_names_k1_bool = clustersPerGene[,'1'] > 0
wbid_names_k2_bool = clustersPerGene[,'2'] > 0
wbid_names_k3_bool = clustersPerGene[,'3'] > 0
wbid_names_k4_bool = clustersPerGene[,'4'] > 0

wbid_clusters= list(k0=wbid_rownames[wbid_names_k0_bool],
                    k1=wbid_rownames[wbid_names_k1_bool],
                    k2=wbid_rownames[wbid_names_k2_bool],
                    k3=wbid_rownames[wbid_names_k3_bool], 
                    k4=wbid_rownames[wbid_names_k4_bool])

library(UpSetR);
wbid_clusters_fromlist = fromList(wbid_clusters)

upset(wbid_clusters_fromlist, 
      sets=rev(c("k1", "k2", "k3", "k4","k0")), 
      mainbar.y.label = "Geneset intersections", 
      sets.x.label="# of genes in cluster",
      set_size.show=T,
      group.by="degree",
      text.scale=1.5, 
      keep.order = T,
      query.legend = "top", 
      nintersects=NA, 
      order.by = "degree", decreasing=F)

#  sum(311, 270, 876, 1544, 2153)

# breakdown of genes with multiple peaks
clustersPerGene_rowSums = rowSums(clustersPerGene)
multiple_peaks = clustersPerGene_rowSums > 1
sum(multiple_peaks) # 2280
breakdown=table(clustersPerGene_rowSums)
bp=barplot(table(clustersPerGene_rowSums), xlab="number of peaks mapped to a gene", ylab="number of genes", main="Genes tend to have a single peak mapped to them")
i=1; y=breakdown[i]; text(bp[i,1],y - strheight(y,srt=90)*1.9,srt=90, labels = y)
for (i in 2:10) { y=breakdown[i]; text(bp[i,1],y + strheight(y,srt=90)*1.66,srt=90, labels = y) }

# to create this plot in a separate file:
if (FALSE)
{
  pdf(file="fig1.pdf")
  print(ggplot(trends_ordered_long, aes(x=stage,y=center, group=description,colour=description )) + geom_line(size = 1.5) + labs(title=label, y = "cluster center (Z)", x = "developmental stage"))  
  dev.off()
}

# some scoring metrics
ap.tbl %>% mutate(meanOccupancy=(LE_nonNormed+L1_nonNormed+L3_nonNormed)/3) -> ap.tbl
ap.tbl %>% mutate(weightedVariance=variance*k4weights) -> ap.tbl
ap.tbl %>% mutate(coeffVariation=sqrt(variance)/meanOccupancy) -> ap.tbl
# selection criterium "score" is coefficient of variation for class 0, weightedVariance
# for classes 1-4.

ap.tbl %>% mutate(selectionScore=ifelse(k4cluster==0, coeffVariation, weightedVariance)) -> ap.tbl

# apply IDR rules
ap.tbl %>% filter(k4cluster==0) %>% filter(LE_IDR == 1 & L1_IDR == 1 & L3_IDR == 1) -> ap.tbl.0
ap.tbl %>% filter(k4cluster==1) %>% filter(LE_IDR==1)                               -> ap.tbl.1
ap.tbl %>% filter(k4cluster==2) %>% filter(L1_IDR == 1 & L3_IDR == 1)               -> ap.tbl.2
ap.tbl %>% filter(k4cluster==3) %>% filter(L3_IDR == 1)                             -> ap.tbl.3
ap.tbl %>% filter(k4cluster==4) %>% filter(L3_IDR & (L1_IDR | LE_IDR))              -> ap.tbl.4

# Map the coefficient of variation to (lowest->1, hightest->0)
inverseScale = function(x, minVal, rangeVal) { y = (x-minVal)/rangeVal; return(1-y);}
ap.tbl.0 %>% select(coeffVariation) %>% min() -> min_cov.0
ap.tbl.0 %>% select(coeffVariation) %>% range() %>% diff() -> range_cov.0
ap.tbl.0 %>% mutate(selectionScore=inverseScale(coeffVariation, min_cov.0, range_cov.0))

ap.tbl.0 %>% arrange(desc(selectionScore)) -> ap.tbl.scored
ap.tbl.1 %>% arrange(desc(selectionScore)) %>% bind_rows(ap.tbl.scored) -> ap.tbl.scored
ap.tbl.2 %>% arrange(desc(selectionScore)) %>% bind_rows(ap.tbl.scored) -> ap.tbl.scored
ap.tbl.3 %>% arrange(desc(selectionScore)) %>% bind_rows(ap.tbl.scored) -> ap.tbl.scored
ap.tbl.4 %>% arrange(desc(selectionScore)) %>% bind_rows(ap.tbl.scored) -> ap.tbl.scored


ap$weightedVariance = ap$variance * ap$k4weights
ap.0 = ap[ap$k4cluster == 0]
ap.1 = ap[ap$k4cluster == 1]
ap.2 = ap[ap$k4cluster == 2]
ap.3 = ap[ap$k4cluster == 3]
ap.4 = ap[ap$k4cluster == 4]

# enforce meaningful constraint on called, reproducible peaks for given pattern
ap.0.IDR = ap.0[ap.0$LE_IDR == 1 & ap.0$L1_IDR == 1 & ap.0$L3_IDR == 1]
ap.1.IDR = ap.1[ap.1$LE_IDR==1]
ap.2.IDR = ap.2[ap.2$L1_IDR == 1 & ap.2$L3_IDR == 1]
ap.3.IDR = ap.3[ap.1$L3_IDR == 1]
ap.4.IDR = ap.4[ap.4$L3_IDR & (ap.4$L1_IDR | ap.4$LE_IDR)] 


# coeffecient of variation for Non-changing class
coefVar = function(x) {sd(x) / mean(x)}
cov.0.IDR = apply(
  as.matrix(mcols(ap.0.IDR)[, c('LE_nonNormed', 'L1_nonNormed', 'L3_nonNormed')]), 
  1, coefVar)

ap.0.IDR = ap.0.IDR[order(-cov.0.IDR)] 
ap.1.IDR = ap.1.IDR[order(-ap.1.IDR$weightedVariance)]
ap.2.IDR = ap.2.IDR[order(-ap.2.IDR$weightedVariance)]
ap.3.IDR = ap.3.IDR[order(-ap.3.IDR$weightedVariance)]
ap.4.IDR = ap.4.IDR[order(-ap.4.IDR$weightedVariance)]

ap.0.IDR[1:20]


top=50

grformat = function(granges) {
  df = as.data.frame(granges)
  df$strand <- NULL
  return(df)
}


# see previous commits for attempts to characterize the cluster patterns
```

``` {r GO term analysis}
attach(annotatedPeaks)


# get the annotations from PARASITE
if (! "paramart" %in% ls()) {
  system.time({paramart <- useMart("parasite_mart", dataset = "wbps_gene", host = "https://parasite.wormbase.org", port = 443)})}
if (! "WORMGO" %in% ls()) {
  # go to https://parasite.wormbase.org/biomart/martview/ to figure out the values to use for this
  system.time({WORMGO = biomaRt::getBM(
    mart = paramart,
    filter = "species_id_1010",
    value = "caelegprjna13758",
    attributes = c(
      "wbps_gene_id",
      "external_gene_id",
      "go_accession",
      "go_name_1006",
      "go_linkage_type"
    )
  )}) 
}

# create an object where you can access all the GO terms that are assigned to a specific gene
geneID2GO <- by(WORMGO$go_accession, WORMGO$wbps_gene_id, function(x) as.character(x))


# All possible genes
all.genes <- unique(as.character(WORMGO$wbps_gene_id))
geneList = factor(as.integer(all.genes %in% all_CDS_genes$wbps_gene_id))
names(geneList) = all.genes

BP.go = new("topGOdata", ontology='BP'
, allGenes = geneList
, annot = annFUN.gene2GO
, gene2GO = geneID2GO)

MF.go = new("topGOdata", ontology='MF'
, allGenes = geneList
, annot = annFUN.gene2GO
, gene2GO = geneID2GO)

CC.go = new("topGOdata", ontology='CC'
, allGenes = geneList
, annot = annFUN.gene2GO
, gene2GO = geneID2GO)

GOSummary<- function(GOdata) {
  test.stat <- new("classicCount", testStatistic = GOFisherTest, name = "Fisher test")
  resultFis <- getSigGroups(GOdata, test.stat)
  test.stat <- new("classicScore", testStatistic = GOKSTest, name = "KS tests")
  resultKS <- getSigGroups(GOdata, test.stat)
  test.stat <- new("elimCount", testStatistic = GOFisherTest, name = "Fisher test",cutOff = 0.01)
  resultElim <- getSigGroups(GOdata, test.stat)
  test.stat <- new("weightCount", testStatistic = GOFisherTest, name = "Fisher test", sigRatio = "ratio")
  resultWeight <- getSigGroups(GOdata, test.stat)
  l <- list(classic = resultFis, KS = resultKS, elim = resultElim,weight = resultWeight)
  return(GenTable(object=GOdata, weight=l$weight, classic=l$classic, elim=l$elim, KS=l$KS, orderBy="weight",ranksOf = "classic", topNodes = 50))
}

## algorithm weight01 performs a traversal of the DAG 
# BP.results.01f = runTest(BP.go, algorithm = "weight01", statistic="fisher")
# peakset.BP.results.tab <- GenTable(object = BP.go, elimFisher = BP.results.01f)
# showSigOfNodes(BP.go, score(BP.results.01f),useInfo = 'all' ,firstSigNodes = 10)
# 
# MF.go = new("topGOdata", ontology='MF'
# , allGenes = geneList
# , annot = annFUN.gene2GO
# , gene2GO = geneID2GO)
# GOdata=MF.go
# MF.results <- runTest(MF.go, algorithm = "weight01", statistic = "fisher")
# MF.results.tab <- GenTable(object = MF.go, elimFisher = MF.results)
# 
# 
# CC.go = new("topGOdata", ontology='CC'
# , allGenes = geneList
# , annot = annFUN.gene2GO
# , gene2GO = geneID2GO)
# GOdata = CC.go
# CC.results <- runTest(CC.go, algorithm = "weight01", statistic = "fisher")
# CC.results.tab <- GenTable(object = CC.go, elimFisher = CC.results, topNodes=20)
unique.ap.wbid=all.genes
# Sub clusters vs all peaks

#0
unique.clust_0_wbid = unique(bycluster$ap_0$feature);
geneList = factor(as.integer(unique.ap.wbid %in% unique.clust_0_wbid))
names(geneList) = unique.ap.wbid
BP.go = new("topGOdata", ontology='BP'
, allGenes = geneList
, annot = annFUN.gene2GO
, gene2GO = geneID2GO)

#BP.results.01f = runTest(BP.go, algorithm = "weight01", statistic="fisher")
#BP.results.k0.tab <- GenTable(object = BP.go, elimFisher = BP.results.01f, topNodes=20)
K0_allBPRes = GOSummary(BP.go)

#1
unique.clust_1_wbid = unique(bycluster$ap_1$feature);
geneList = factor(as.integer(unique.ap.wbid %in% unique.clust_1_wbid))
names(geneList) = unique.ap.wbid
BP.go = new("topGOdata", ontology='BP'
, allGenes = geneList
, annot = annFUN.gene2GO
, gene2GO = geneID2GO)

# algo weight01 performs a conditional traversal of the DAG
#BP.results.01f = runTest(BP.go, algorithm = "weight01", statistic="fisher")
#BP.results.k1.tab <- GenTable(object = BP.go, elimFisher = BP.results.01f, topNodes=20)
K1_allBPRes = GOSummary(BP.go)
kable(K1_allBPRes[order(K1_allBPRes$elim),][K1_allBPRes$Significant > 2,])
#2
unique.clust_2_wbid = unique(bycluster$ap_2$feature);
geneList = factor(as.integer(unique.ap.wbid %in% unique.clust_2_wbid))
names(geneList) = unique.ap.wbid
BP.go = new("topGOdata", ontology='BP'
, allGenes = geneList
, annot = annFUN.gene2GO
, gene2GO = geneID2GO)

# algo weight01 performs a conditional traversal of the DAG
# BP.results.01f = runTest(BP.go, algorithm = "weight01", statistic="fisher")
# BP.results.k2.tab <- GenTable(object = BP.go, elimFisher = BP.results.01f, topNodes=20)
K2_allBPRes = GOSummary(BP.go)
kable(K2_allBPRes[order(K2_allBPRes$elim),][K2_allBPRes$Significant > 2,])
#3
unique.clust_3_wbid = unique(bycluster$ap_3$feature);
geneList = factor(as.integer(unique.ap.wbid %in% unique.clust_3_wbid))
names(geneList) = unique.ap.wbid
BP.go = new("topGOdata", ontology='BP'
, allGenes = geneList
, annot = annFUN.gene2GO
, gene2GO = geneID2GO)

# algo weight01 performs a conditional traversal of the DAG
# BP.results.01f = runTest(BP.go, algorithm = "weight01", statistic="fisher")
# BP.results.k3.tab <- GenTable(object = BP.go, elimFisher = BP.results.01f, topNodes=20)
K3_allBPRes = GOSummary(BP.go)
kable(K3_allBPRes[order(K3_allBPRes$elim),][K3_allBPRes$Significant > 2,])
#4
unique.clust_4_wbid = unique(bycluster$ap_4$feature);
geneList = factor(as.integer(unique.ap.wbid %in% unique.clust_4_wbid))
names(geneList) = unique.ap.wbid
BP.go = new("topGOdata", ontology='BP'
, allGenes = geneList
, annot = annFUN.gene2GO
, gene2GO = geneID2GO)

# algo weight01 performs a conditional traversal of the DAG
# BP.results.01f = runTest(BP.go, algorithm = "weight01", statistic="fisher")
# BP.results.k4.tab <- GenTable(object = BP.go, elimFisher = BP.results.01f, topNodes=20)
K4_allBPRes = GOSummary(BP.go)


K3_allBPRes[order(K3_allBPRes$elim),][K3_allBPRes$Significant > 2,] -> bestK3terms; View(bestK3terms)
K4_allBPRes[order(K4_allBPRes$elim),][K4_allBPRes$Significant > 2,] -> bestK4terms; View(bestK4terms)
K2_allBPRes[order(K2_allBPRes$elim),][K2_allBPRes$Significant > 2,] -> bestK2terms; View(bestK2terms)
K1_allBPRes[order(K1_allBPRes$elim),][K1_allBPRes$Significant > 2,] -> bestK1terms; View(bestK1terms)
K0_allBPRes[order(K0_allBPRes$elim),][K0_allBPRes$Significant > 2,] -> bestK0terms; View(bestK0terms)
```
